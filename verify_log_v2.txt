üîç Starting Mission B Router Verification...

[TEST 1] Checking Provider Configuration...
Enabled Providers: gemini, claude, groq, openrouter
‚úÖ gemini: Key format valid
‚úÖ claude: Key format valid
‚úÖ groq: Key format valid
‚úÖ openrouter: Key format valid
‚úÖ Provider redundancy check passed.

[TEST 2] Checking Router State...
Initial Router Stats: {
  "enabledProviders": [
    "gemini",
    "claude",
    "groq",
    "openrouter"
  ],
  "currentIndex": 0,
  "requestCounts": {}
}
‚úÖ Router state matches configuration.

[TEST 3] Performing Live connectivity test (Logic Category)...
[LLM Router] Attempting gemini for logic task
[LLM Router] ‚ùå gemini failed: {"error":{"code":404,"message":"models/gemini-2.0-flash-thinking-exp is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.","status":"NOT_FOUND"}}
[LLM Router] Attempting claude for logic task
[LLM Router] ‚ùå claude failed: 400 {"type":"error","error":{"type":"invalid_request_error","message":"Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits."},"request_id":"req_011CWzzkmoibkDo1p6x6Xt64"}
[LLM Router] Attempting groq for logic task
[LLM Router] ‚ùå groq failed: 400 {"error":{"message":"The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}
[LLM Router] Attempting openrouter for logic task
[LLM Router] ‚úÖ Success with openrouter
Response received from: openrouter
Model used: anthropic/claude-3.5-haiku
Text: "4"
Latency: 1301ms
‚úÖ Live test successful: Logic Verified.

üîç Verification Complete.
